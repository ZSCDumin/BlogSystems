---
title: 爬虫
date: 2018-03-28 13:08:05
tags:
---

### 1.创建项目 
>+ scrapy startproject p1

### 2.文件说明：
>+ scrapy.cfg  项目的配置信息，主要为Scrapy命令行工具提供一个基础的配置信息。（真正爬虫相关的配置信息在settings.py文件中）
items.py    设置数据存储模板，用于结构化数据，如：Django的Model
pipelines    数据处理行为，如：一般结构化的数据持久化
settings.py 配置文件，如：递归的层数、并发数，延迟下载等
spiders      爬虫目录，如：创建文件，编写爬虫规则
注意：一般创建爬虫文件时，以网站域名命名

### 3.编写爬虫
>+ 在spiders目录中新建 xiaohuar_spider.py 文件

###4.运行
>+ 进入p1目录，运行命令scrapy crawl xiaohau --nolog
>+ 格式：scrapy crawl+爬虫名  –nolog即不显示日志

[注]: scrapy 报错 no module named win32api解决方案如下：
>+    pip install pypiwin32