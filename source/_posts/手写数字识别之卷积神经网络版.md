---
title: 手写数字识别之卷积神经网络版
date: 2018-06-26 17:14:31
tags:
---

# 参考代码如下：

```python
import numpy
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.utils import np_utils
from keras import backend as K   # backend 是一个后端引擎，主要有三种：Theano/Tensorflow/CNTK
K.set_image_dim_ordering('th') # th与tf的区别就是参数填写位置的区别: th(28,28,3), tf(3,28,28) 【3代表通道数，其他两个参数代表图片像素大小】
```


```python
# 随机种子确保结果可再现
seed = 7
numpy.random.seed(seed)
```


```python
# 加载数据
(X_train, y_train), (X_test, y_test) = mnist.load_data() # X_train 代表一张图片，y_train 代表图片对应的数字；X_test 代表一张图片，y_test 代表图片对应的数字

# 重新改变大小为： [样本数目][通道数][图片宽][图片高]
X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')
X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')
```


```python
# 将灰度值0-255范围归一化映射为0-1之间
X_train = X_train / 255
X_test = X_test / 255

# 模型的输出是对每个类别的打分预测，对于分类结果从0-9的每个类别都有一个预测分值，表示将模型输入预测为该类的概率大小，概率越大可信度越高。
# 由于原始的数据标签是0-9的整数值，通常将其表示成0ne-hot向量。如第一个训练数据的标签为5，one-hot表示为[0,0,0,0,0,1,0,0,0,0]。
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
num_classes = y_test.shape[1] # y_test.shape(10000,10)
```


```python
# 定义模型函数
def baseline_model():
    # 创建模型
    model = Sequential()
    # 设置模型参数
    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu')) # 32个filter ,每个filter大小为5 x 5；单通道，图片大小28 x 28
    model.add(MaxPooling2D(pool_size=(2, 2))) # 最大池化矩阵 2 x 2，池化的最主要作用就是压缩数据和参数。
    model.add(Dropout(0.3))  # 控制需要断开的链接的比例，可以减轻过拟合现象，一般设为0.3或者0.5。
    model.add(Flatten())# Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。
    model.add(Dense(128, activation='relu')) # 全连接层128个单元
    model.add(Dense(num_classes, activation='softmax')) # 输出层只能为10个单元
    # 编译模型
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #选择了交叉编译，Adam优化器
    return model
```


```python
# 开始编译模型
model = baseline_model()
```


```python
# 训练模型
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)

# 评估模型
loss , scores = model.evaluate(X_test, y_test, verbose=1)

# 输出Loss值和评分
print("Loss: ", loss)
print("scores: ", scores)
```

    Train on 60000 samples, validate on 10000 samples
    Epoch 1/10
     - 6s - loss: 0.2400 - acc: 0.9314 - val_loss: 0.0837 - val_acc: 0.9740
    Epoch 2/10
     - 6s - loss: 0.0779 - acc: 0.9765 - val_loss: 0.0482 - val_acc: 0.9843
    Epoch 3/10
     - 6s - loss: 0.0560 - acc: 0.9827 - val_loss: 0.0431 - val_acc: 0.9861
    Epoch 4/10
     - 6s - loss: 0.0433 - acc: 0.9866 - val_loss: 0.0423 - val_acc: 0.9857
    Epoch 5/10
     - 6s - loss: 0.0363 - acc: 0.9883 - val_loss: 0.0333 - val_acc: 0.9884
    Epoch 6/10
     - 6s - loss: 0.0301 - acc: 0.9906 - val_loss: 0.0310 - val_acc: 0.9893
    Epoch 7/10
     - 6s - loss: 0.0246 - acc: 0.9922 - val_loss: 0.0316 - val_acc: 0.9888
    Epoch 8/10
     - 6s - loss: 0.0232 - acc: 0.9927 - val_loss: 0.0296 - val_acc: 0.9896
    Epoch 9/10
     - 6s - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0284 - val_acc: 0.9906
    Epoch 10/10
     - 6s - loss: 0.0164 - acc: 0.9949 - val_loss: 0.0282 - val_acc: 0.9911
    10000/10000 [==============================] - 1s 85us/step
    Loss:  0.0281819745783
    scores:  0.9911
